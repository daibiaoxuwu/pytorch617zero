# end2end.py
from __future__ import division
import os
import sys
from datetime import datetime
import torch.nn.functional as F

from scipy.signal import chirp, spectrogram
import warnings

warnings.filterwarnings("ignore")

# Torch imports
import torch
import torch.fft
import torch.nn as nn
import torch.optim as optim

# Numpy & Scipy imports
import numpy as np
import scipy.io

import cv2
# Local imports
from utils import *
import torch.autograd.profiler as profiler
import time
import math
import scipy.io as scio


def checkpoint(iteration, models, opts):
    mask_CNN_path = os.path.join(opts.checkpoint_dir, str(iteration) + '_maskCNN.pkl')
    create_dir(opts.checkpoint_dir)
    torch.save(models[0].state_dict(), mask_CNN_path)
    if opts.cxtoy == 'True':
        C_XtoY_path = os.path.join(opts.checkpoint_dir, str(iteration) + '_C_XtoY.pkl')
        torch.save(models[1].state_dict(), C_XtoY_path)
    print('CKPT: ', mask_CNN_path)

def binary(y):
    y[abs(y)>0.5] = 1
    y[abs(y)<=0.5] = 0
    return y

def merge_images(sources, targets, Y, test_right_case, opts):
    """Creates a grid consisting of pairs of columns, where the first column in
    each pair contains images source images and the second column in each pair
    contains images generated by the CycleGAN from the corresponding images in
    the first column.
    """
    _, _, h, w = sources[0].shape
    row = 1# int(np.sqrt(opts.batch_size))
    column = 1# math.ceil(opts.batch_size / row)
    merged = np.zeros([opts.y_image_channel, row * h , column * w * opts.stack_imgs * 3])
    for stack_idx in range(opts.stack_imgs):
        for idx, (s, t, y, c) in enumerate(zip(sources[stack_idx], targets[stack_idx], Y[stack_idx], test_right_case)):
            i = idx // column
            j = idx % column
            merged[:, i * h:(i + 1) * h,  (j * 3 * opts.stack_imgs + stack_idx*3)     * w:(j * 3 * opts.stack_imgs + 1 + stack_idx*3) * w,] = s
            merged[:, i * h:(i + 1) * h,  (j * 3 * opts.stack_imgs + stack_idx*3 + 1) * w:(j * 3 * opts.stack_imgs + 2 + stack_idx*3) * w,] = t
            merged[:, i * h:(i + 1) * h,  (j * 3 * opts.stack_imgs + stack_idx*3 + 2) * w:(j * 3 * opts.stack_imgs + 3 + stack_idx*3) * w,] = y
            break
    merged = merged.transpose(1, 2, 0)
    newsize = ( merged.shape[1] ,merged.shape[1] * opts.stack_imgs )
    #return cv2.resize(merged, dsize=newsize)
    return merged


def save_samples(iteration, fixed_Y, fixed_X, mask_CNN, test_right_case, name, opts):
    """Saves samples from both generators X->Y and Y->X.
    """
    if opts.model_ver == 0: fake_Y = mask_CNN(torch.cat(fixed_X,1))
    else: fake_Y = mask_CNN(fixed_X)
    fixed_X = [to_data(i) for i in fixed_X]

    Y, fake_Y = [to_data(i) for i in fixed_Y], [to_data(i) for i in fake_Y]

    mergeda = merge_images(fixed_X, fake_Y, Y, test_right_case, opts)

    path = os.path.join(opts.checkpoint_dir,
            'sample-{:06d}-snr{:.1f}-Y{:s}.png'.format(iteration,opts.snr_list[0],name))
    merged = np.abs(mergeda[:, :, 0]+1j*mergeda[:, :, 1])
    merged = (merged - np.min(merged)) / (np.max(merged) - np.min(merged)) * 255
    merged = cv2.flip(merged, 0)
    #print(np.max(merged),np.min(merged),np.mean(merged))
    cv2.imwrite(path, merged)
    print('SAVED TEST SAMPLE: {}'.format(path))


def training_loop(dataloader, models, opts):
    """Runs the training loop.
        * Saves checkpoint every opts.checkpoint_every iterations
    """
    mask_CNN = models[0]
    if opts.cxtoy == 'True': C_XtoY = models[1] 
    loss_spec = torch.nn.MSELoss(reduction='mean')
    loss_class = nn.CrossEntropyLoss()


    # load downchirp

    if opts.dechirp == 'True':
        nsamp = int(opts.fs * opts.n_classes / opts.bw)
        t = np.linspace(0, nsamp / opts.fs, nsamp)
        chirpI1 = chirp(t, f0=opts.bw/2, f1=-opts.bw/2, t1=2** opts.sf / opts.bw , method='linear', phi=90)
        chirpQ1 = chirp(t, f0=opts.bw/2, f1=-opts.bw/2, t1=2** opts.sf / opts.bw, method='linear', phi=0)
        dechirp = chirpI1+1j*chirpQ1
        

        downchirp1 = torch.tensor(dechirp, dtype=torch.cfloat).cuda()

        downchirp = torch.stack([ torch.stack([ downchirp1 for i in range(opts.stack_imgs)])for i in range(opts.batch_size)])
        downchirpY = torch.stack([ downchirp1 for i in range(opts.batch_size)])


    
    # Create generators and discriminators
    
    g_params = list(mask_CNN.parameters()) 
    if opts.cxtoy == 'True': g_params += list(C_XtoY.parameters())
    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])

    G_Y_loss_avg = []
    G_Image_loss_avg = []
    G_Class_loss_avg = []
    G_Acc = 0

    iteration = opts.init_train_iter
    oldtime = time.time()#time the training process

    scoreboards = [0, 0,]

    trim_size = opts.freq_size // 2

    print('   CURRENT TIME       ITER  YLOSS  ILOSS  CLOSS   ACC   TIME  ----TRAINING',opts.lr,'----')
    while iteration<=opts.init_train_iter+opts.train_iters:
            images_X, labels_X, images_Y, data_file_name = next(dataloader.__iter__())
            iteration+=1

            mask_CNN.train()
            if opts.cxtoy == 'True':C_XtoY.train()


            images_X = to_var(images_X)
            images_Y = to_var(torch.tensor(images_Y[0], dtype=torch.cfloat))
            if opts.dechirp == 'True': images_X = images_X * downchirp
            if opts.dechirp == 'True': images_Y = images_Y * downchirpY
            images_X_spectrum = []
            images_Y_spectrum = []
            for i in range(opts.stack_imgs):
                images_X_spectrum_raw = torch.stft(input=images_X.select(1,i), n_fft=opts.stft_nfft, 
                                                    hop_length=opts.stft_overlap , win_length=opts.stft_window ,
                                                    pad_mode='constant',return_complex=True)
                images_X_spectrum.append(spec_to_network_input2( spec_to_network_input(images_X_spectrum_raw, opts), opts ))
            
                images_Y_spectrum_raw = torch.stft(input=images_Y, n_fft=opts.stft_nfft, 
                                                    hop_length=opts.stft_overlap , win_length=opts.stft_window ,
                                                    pad_mode='constant',return_complex=True)
                images_Y_spectrum_raw = spec_to_network_input(images_Y_spectrum_raw, opts)
                images_Y_spectrum_raw = spec_to_network_input2(images_Y_spectrum_raw, opts)
                images_Y_spectrum.append(images_Y_spectrum_raw)

            
            #########################################
            ##              FORWARD
            #########################################
            g_optimizer.zero_grad()
            G_Y_loss = 0
            G_Image_loss = 0
            G_Class_loss = 0
            if opts.model_ver == 0:
                fake_Y_spectrum = mask_CNN(torch.cat(images_X_spectrum,1))
                for i in range(opts.stack_imgs):
                    g_y_pix_loss = loss_spec(fake_Y_spectrum[:,i*2:i*2+2,:,:], images_Y_spectrum[i])
                    labels_X_estimated = C_XtoY(fake_Y_spectrum[:,i*2:i*2+2,:,:])
                    g_y_class_loss = loss_class(labels_X_estimated, labels_X)
                    G_Image_loss = opts.w_image * g_y_pix_loss
                    G_Class_loss = g_y_class_loss
                    G_Y_loss += opts.w_image * g_y_pix_loss + g_y_class_loss 
                    _, labels_X_estimated = torch.max(labels_X_estimated, 1)
                    test_right_case = to_data(labels_X_estimated == labels_X)
                    G_Acc += np.sum(test_right_case)/opts.stack_imgs
            else: 
                #with torch.no_grad():
                fake_Y_spectrums = mask_CNN(images_X_spectrum) #CNN input: a list of images, output: a list of images
                for i in range(opts.stack_imgs):
                    fake_Y_spectrum = fake_Y_spectrums[i]
                    g_y_pix_loss = loss_spec(torch.abs(fake_Y_spectrum[:,0]+1j*fake_Y_spectrum[:,1]), torch.abs(images_Y_spectrum[0][:,0]+1j*images_Y_spectrum[0][:,1]))

                    G_Image_loss += opts.w_image * g_y_pix_loss / opts.stack_imgs
                    if opts.cxtoy == 'True':
                        labels_X_estimated = C_XtoY(fake_Y_spectrum)
                    else:
                        fake_Y_test_spectrum2 = spec_to_network_input(torch.abs(fake_Y_spectrum[:,0,:,:] + 1j*fake_Y_spectrum[:,1,:,:]), opts)
                        labels_X_estimated = F.softmax(fake_Y_test_spectrum2.sum(-1),dim=1)
                    g_y_class_loss = loss_class(labels_X_estimated, labels_X)
                    G_Class_loss += g_y_class_loss / opts.stack_imgs
                    _, labels_X_estimated = torch.max(labels_X_estimated, 1)
                    test_right_case = to_data(labels_X_estimated == labels_X)
                    G_Acc += np.sum(test_right_case)


                G_Y_loss = G_Image_loss + G_Class_loss 
            G_Y_loss.backward()
            g_optimizer.step()

            
            #########################################
            ##     LOG THE LOSS OF LATEST opts.log_step*5 STEPS
            #########################################
            if len(G_Y_loss_avg)<opts.log_step:
                G_Y_loss_avg.append(G_Y_loss.item())
                G_Image_loss_avg.append(G_Image_loss.item())
                G_Class_loss_avg.append(G_Class_loss.item())
                #if opts.cxtoy == 'True': G_Class_loss_avg.append(G_Class_loss.item())
                #else: G_Class_loss_avg.append(0)
            else:
                G_Y_loss_avg[iteration % opts.log_step] = G_Y_loss.item()
                G_Image_loss_avg[iteration % opts.log_step] = G_Image_loss.item()
                G_Class_loss_avg[iteration % opts.log_step] = G_Class_loss.item()
                #if opts.cxtoy == 'True': G_Class_loss_avg[iteration % opts.log_step] = G_Class_loss.item()
                #else: G_Class_loss_avg[iteration % opts.log_step] = 0
            if iteration % opts.log_step == 0:
                output_lst = ["{:6d}".format(iteration),
                                "{:6.3f}".format(np.mean(G_Y_loss_avg)),
                                "{:6.3f}".format(np.mean(G_Image_loss_avg)),
                                "{:6.3f}".format(np.mean(G_Class_loss_avg)),
                                "{:6.3f}".format(G_Acc / opts.log_step / opts.batch_size / opts.stack_imgs),
                                "{:6.3f}".format(time.time() - oldtime)]
                output_str = str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")) + ' ' + ' '.join(output_lst)
                oldtime = time.time()
                print(output_str)
                with open(opts.logfile,'a') as f:
                    f.write('\n'+str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")) + ' , ' + ' , '.join(output_lst))
                G_Acc = 0

            ## checkpoint
            if (iteration) % opts.checkpoint_every == 0:
                checkpoint(iteration, models, opts)

            ## test
            if iteration % opts.test_step == 1:# or iteration == opts.init_train_iter + opts.train_iters:
                mask_CNN.eval()
                if opts.cxtoy == 'True':C_XtoY.eval()
                with torch.no_grad():
                    #print('start testing..')
                    error_matrix = 0
                    error_matrix_count = 0
                    iteration2 = 0
                    G_Image_loss_avg_test = 0
                    G_Class_loss_avg_test = 0
                    sample_cnt = 0
                    while iteration2 < opts.max_test_iters: 
                            images_X_test, labels_X_test, images_Y_test0, data_file_name = next(dataloader.__iter__())
                            iteration2 += 1
                            labels_X_test = labels_X_test.cuda()

                            images_X_test, labels_X_test = to_var(images_X_test), to_var(labels_X_test)
                            images_Y_test = to_var(images_Y_test0[0])
                            images_X_test_spectrum = []
                            images_Y_test_spectrum = []
                            if opts.dechirp == 'True': images_X_test = images_X_test* downchirp
                            if opts.dechirp == 'True': images_Y_test = images_Y_test * downchirpY
                            for i in range(opts.stack_imgs):
                                images_X_test_spectrum_raw = torch.stft(input=images_X_test.select(1,i), n_fft=opts.stft_nfft, #(opts.n_classes* opts.fs // opts.bw)
                                                    hop_length=opts.stft_overlap , win_length=opts.stft_window ,
                                                    pad_mode='constant',return_complex=True)
                                images_X_test_spectrum.append(spec_to_network_input2(spec_to_network_input(images_X_test_spectrum_raw, opts),opts))

                                images_Y_test_spectrum_raw = torch.stft(input=images_Y_test, n_fft=opts.stft_nfft,
                                                    hop_length=opts.stft_overlap, win_length=opts.stft_window,
                                                    pad_mode='constant',return_complex=True)
                                images_Y_test_spectrum_raw = spec_to_network_input(images_Y_test_spectrum_raw, opts)

                                images_Y_test_spectrum_raw = spec_to_network_input2(images_Y_test_spectrum_raw, opts)
                                images_Y_test_spectrum.append(images_Y_test_spectrum_raw)

                            # forward
                            if opts.model_ver == 0: 
                                fake_Y_test_spectrum = mask_CNN(torch.cat(images_X_test_spectrum, 1))
                                labels_X_estimated = C_XtoY(fake_Y_test_spectrum[:,:2,:,:])
                                g_y_pix_loss = loss_spec(fake_Y_test_spectrum[:,:2,:,:], images_Y_test_spectrum[0])
                                g_y_class_loss = loss_class(labels_X_estimated, labels_X_test)
                                G_Image_loss_avg_test += g_y_pix_loss.item() 
                                G_Class_loss_avg_test += g_y_class_loss.item() 
                            else: 
                                fake_Y_test_spectrums = mask_CNN(images_X_test_spectrum) #CNN input: a list of images, output: a list of images
                                for fake_Y_test_spectrum in fake_Y_test_spectrums:
                                    g_y_pix_loss = loss_spec(fake_Y_test_spectrum, images_Y_test_spectrum[0])
                                    if opts.cxtoy=='True':
                                        labels_X_estimated = C_XtoY(fake_Y_test_spectrum)
                                    else:
                                        fake_Y_test_spectrums = [spec_to_network_input(torch.abs(x[:,0,:,:] + 1j*x[:,1,:,:]), opts) for x in fake_Y_test_spectrums]
                                        fake_Y_test_spectrum3 = torch.stack(fake_Y_test_spectrums,0)
                                        labels_X_estimated =  F.softmax(fake_Y_test_spectrum3.sum(0).sum(-1),dim=1)#.reshape(opts.batch_size, opts.n_classes)


                                    g_y_class_loss = loss_class(labels_X_estimated, labels_X_test)
                                    G_Image_loss_avg_test += g_y_pix_loss.item() 
                                    G_Class_loss_avg_test += g_y_class_loss.item() 

                                    _, labels_X_test_estimated = torch.max(labels_X_estimated, 1)
                                    test_right_case = to_data(labels_X_test_estimated == labels_X_test)
                                    error_matrix += np.sum(test_right_case)

                                    error_matrix_count += opts.batch_size

                            if(sample_cnt==0 and  np.sum(test_right_case) < opts.batch_size  ):
                                sample_cnt+=1
                                #print(labels_X_test_estimated, labels_X_test,test_right_case.astype(np.int))
                                save_samples(iteration+iteration2, images_Y_test_spectrum, images_X_test_spectrum, mask_CNN, test_right_case, 'val', opts)

                    error_matrix2 = error_matrix / error_matrix_count
                    print('TEST: ACC:' ,error_matrix2, '['+str(error_matrix)+'/'+str(error_matrix_count)+']','ILOSS:',"{:6.3f}".format(G_Image_loss_avg_test/error_matrix_count*opts.batch_size*opts.w_image) ,'CLOSS:',"{:6.3f}".format(G_Class_loss_avg_test/error_matrix_count*opts.batch_size))
                    with open(opts.logfile2,'a') as f:
                        f.write('\n'+str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")) + ' , ' + "{:6d}".format(iteration) +  ' , ' + "{:6.3f}".format(error_matrix2))
                    with open(opts.logfile,'a') as f:
                        f.write(' , ' + "{:6d}".format(iteration) +  ' , ' + "{:6.3f}".format(error_matrix2))
                    if(error_matrix2>=opts.terminate_acc):
                        print('REACHED',opts.terminate_acc,'ACC, TERMINATINg...')
                        iteration = opts.init_train_iter + opts.train_iters + 1
                        break
                    print('   CURRENT TIME       ITER  YLOSS  ILOSS  CLOSS   ACC   TIME  ----TRAINING',opts.lr,'----')
    return [mask_CNN, C_XtoY]
