# end2end.py
from __future__ import division
import os
import sys
from datetime import datetime

import warnings

warnings.filterwarnings("ignore")

# Torch imports
import torch
import torch.fft
import torch.nn as nn
import torch.optim as optim

# Numpy & Scipy imports
import numpy as np
import scipy.io

import cv2
# Local imports
from utils import to_var, to_data, spec_to_network_input, create_dir
from model_components import maskCNNModel, classificationHybridModel
import torch.autograd.profiler as profiler
import time

SEED = 11

# Set the random seed manually for reproducibility.
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)





def checkpoint(iteration, mask_CNN, C_XtoY, opts):
    mask_CNN_path = os.path.join(opts.checkpoint_dir, str(iteration) + '_maskCNN.pkl')
    create_dir(opts.checkpoint_dir)
    torch.save(mask_CNN.state_dict(), mask_CNN_path)
    C_XtoY_path = os.path.join(opts.checkpoint_dir, str(iteration) + '_C_XtoY.pkl')
    torch.save(C_XtoY.state_dict(), C_XtoY_path)
    print('model checkpoint saved to', mask_CNN_path, C_XtoY_path)

def merge_images(sources, targets, Y, opts):
    """Creates a grid consisting of pairs of columns, where the first column in
    each pair contains images source images and the second column in each pair
    contains images generated by the CycleGAN from the corresponding images in
    the first column.
    """
    _, _, h, w = sources[0].shape
    row = int(np.sqrt(opts.batch_size))
    column = int(opts.batch_size / row)
    merged = np.zeros([opts.y_image_channel, row * h * opts.stack_imgs, column * w * 3])
    for stack_idx in range(opts.stack_imgs):
        for idx, (s, t, y) in enumerate(zip(sources[stack_idx], targets[stack_idx], Y[stack_idx])):
            i = idx // column
            j = idx % column
            merged[:, (i * opts.stack_imgs + stack_idx) * h:(i * opts.stack_imgs + 1 + stack_idx) * h, (j * 3) * w:(j * 3 + 1) * w] = s
            merged[:, (i * opts.stack_imgs + stack_idx) * h:(i * opts.stack_imgs + 1 + stack_idx) * h, (j * 3 + 1) * w:(j * 3 + 2) * w] = t
            merged[:, (i * opts.stack_imgs + stack_idx) * h:(i * opts.stack_imgs + 1 + stack_idx) * h, (j * 3 + 2) * w:(j * 3 + 3) * w] = y
    return merged.transpose(1, 2, 0)


def save_samples(iteration, fixed_Y, fixed_X, mask_CNN, opts):
    """Saves samples from both generators X->Y and Y->X.
    """
    fake_Y = mask_CNN(fixed_X)
    fixed_X = [to_data(i) for i in fixed_X]

    Y, fake_Y = [to_data(i) for i in fixed_Y], [to_data(i) for i in fake_Y]

    merged = merge_images(fixed_X, fake_Y, Y, opts)

    path = os.path.join(opts.checkpoint_dir,
                        'sample-{:06d}-Y.png'.format(iteration))
    merged = np.abs(merged[:, :, 0] + 1j * merged[:, :, 1])
    merged = (merged - np.amin(merged)) / (np.amax(merged) - np.amin(merged)) * 255
    merged = cv2.flip(merged, 0)
    cv2.imwrite(path, merged)
    print('Saved {}'.format(path))


def training_loop(training_dataloader, testing_dataloader,mask_CNN, C_XtoY, opts):
    """Runs the training loop.
        * Saves checkpoint every opts.checkpoint_every iterations
    """
    loss_spec = torch.nn.MSELoss(reduction='mean')
    loss_class = nn.CrossEntropyLoss()
    
    # Create generators and discriminators
    g_params = list(mask_CNN.parameters()) + list(C_XtoY.parameters())
    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])

    # Maintain Log of average model loss of latest opts.log_step*5 steps
    create_dir(opts.log_dir)
    #opts.logfile = os.path.join(opts.log_dir, 'log' + str(opts.snr_list[0])+'_'+str(opts.snr_list[-1])+'_'+str(opts.stack_imgs) + '.txt')
    #with open(opts.logfile,'a') as f: f.write(str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")) + ' ' +str(sys.argv)+'\n')
    G_Y_loss_avg = []
    G_Image_loss_avg = []
    G_Class_loss_avg = []

    iteration = opts.init_train_iter
    oldtime = time.time()#time the training process

    while iteration < opts.init_train_iter + opts.train_iters:
        train_iter = iter(training_dataloader)
        #print('start new training epoch')
        for images_X, labels_X, images_Y in train_iter:
            mask_CNN.train()
            C_XtoY.train()
            labels_X = labels_X.cuda()
            if iteration>opts.init_train_iter+opts.train_iters:break
            iteration+=1
            if iteration % 3000 == 0:
                opts.lr = opts.lr * 0.85
                g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])
                print('lr',opts.lr)
            if iteration == 10000: opts.scaling_for_imaging_loss /= 2
            if iteration == 20000: opts.scaling_for_imaging_loss /= 2

            images_X = to_var(images_X)
            images_Y = to_var(torch.tensor(images_Y[0], dtype=torch.cfloat))

            # ============================================
            #            GENERATE TRAIING IMAGES
            # ============================================
            images_X_spectrum = [] # training images * opts.stack_imgs
            images_Y_spectrum = [] # training images * opts.stack_imgs
            for i in range(opts.stack_imgs):
                images_X_spectrum_raw = torch.stft(input=images_X.select(1,i), n_fft=opts.stft_nfft, hop_length=opts.stft_overlap,
                                                   win_length=opts.stft_window, pad_mode='constant');
                images_X_spectrum.append( spec_to_network_input(images_X_spectrum_raw, opts) )
            
                images_Y_spectrum_raw = torch.stft(input=images_Y, n_fft=opts.stft_nfft, hop_length=opts.stft_overlap,
                                                   win_length=opts.stft_window, pad_mode='constant');
                images_Y_spectrum.append( spec_to_network_input(images_Y_spectrum_raw, opts) )
            
            #########################################
            ##              FORWARD
            #########################################
            fake_Y_spectrum = mask_CNN(images_X_spectrum) #CNN input: a list of images, output: a list of images
            fake_Y_spectrum = torch.mean(torch.stack(fake_Y_spectrum,0),0) #average of CNN outputs
            
            g_y_pix_loss = loss_spec(fake_Y_spectrum, images_Y_spectrum[0])
            labels_X_estimated = C_XtoY(fake_Y_spectrum)
            g_y_class_loss = loss_class(labels_X_estimated, labels_X)
            g_optimizer.zero_grad()
            G_Image_loss = opts.scaling_for_imaging_loss * g_y_pix_loss
            G_Class_loss = opts.scaling_for_classification_loss * g_y_class_loss
            G_Y_loss = G_Image_loss + G_Class_loss 
            G_Y_loss.backward()
            g_optimizer.step()

            
            #########################################
            ##     LOG THE LOSS OF LATEST opts.log_step*5 STEPS
            #########################################
            if len(G_Y_loss_avg)<opts.log_step*5:
                G_Y_loss_avg.append(G_Y_loss.item())
                G_Image_loss_avg.append(G_Image_loss.item())
                G_Class_loss_avg.append(G_Class_loss.item())
            else:
                G_Y_loss_avg[iteration % opts.log_step*5] = G_Y_loss.item()
                G_Image_loss_avg[iteration % opts.log_step*5] = G_Image_loss.item()
                G_Class_loss_avg[iteration % opts.log_step*5] = G_Class_loss.item()
            if iteration % opts.log_step == 0:
                output_str = str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")) + ' Train Iteration [{:6d}/{:5d}] | G_Y_loss: {:6.4f}| G_Image_loss: {:6.4f}| G_Class_loss: {:6.4f} | Time: {:.2f}' .format(iteration,opts.init_train_iter + opts.train_iters,
                                np.mean(G_Y_loss_avg),
                                np.mean(G_Image_loss_avg),
                                np.mean(G_Class_loss_avg),
                                time.time() - oldtime)
                oldtime = time.time()
                print(output_str)

            ## checkpoint
            if (iteration+1) % opts.checkpoint_every == 0:
                checkpoint(iteration, mask_CNN, C_XtoY, opts)

            ## test
            if iteration % opts.test_step == 1:# or iteration == opts.init_train_iter + opts.train_iters:
                mask_CNN.eval()
                C_XtoY.eval()
                with torch.no_grad():
                    #print('start testing..')
                    error_matrix = [0,0,0,0,0,0,0]
                    error_matrix_count = 0
                    test_iter = iter(testing_dataloader)
                    iteration2 = 0
                    G_Image_loss_avg_test = [0,0,0,0]
                    G_Class_loss_avg_test = [0,0,0,0,0]
                    for images_X_test, labels_X_test, images_Y_test0 in test_iter:
                            if iteration2 >= 100: break
                            iteration2 += 1
                            labels_X_test = labels_X_test.cuda()

                            #prepare testing data
                            images_X_test, labels_X_test = to_var(images_X_test), to_var(labels_X_test)
                            images_Y_test = to_var(images_Y_test0[0])
                            images_X_test_spectrum = []
                            images_Y_test_spectrum = []
                            for i in range(opts.stack_imgs):
                                images_X_test_spectrum_raw = torch.stft(input=images_X_test.select(1,i), n_fft=opts.stft_nfft,
                                                                        hop_length=opts.stft_overlap, win_length=opts.stft_window,
                                                                        pad_mode='constant');
                                images_X_test_spectrum.append(spec_to_network_input(images_X_test_spectrum_raw, opts))

                                images_Y_test_spectrum_raw = torch.stft(input=images_Y_test, n_fft=opts.stft_nfft,
                                                                        hop_length=opts.stft_overlap, win_length=opts.stft_window,
                                                                        pad_mode='constant');
                                images_Y_test_spectrum.append(spec_to_network_input(images_Y_test_spectrum_raw, opts))

                            # forward
                            fake_Y_test_spectrums = mask_CNN(images_X_test_spectrum)
                            labels_X_estimateds = [C_XtoY(i) for i in fake_Y_test_spectrums]
                            labels_X_test_estimateds = torch.stack([torch.max(i, 1)[1] for i in labels_X_estimateds]).double()

                            fake_Y_test_spectrum = torch.mean(torch.stack(fake_Y_test_spectrums,0),0)
                            labels_X_estimated = C_XtoY(fake_Y_test_spectrum)
                            fake_Y_test_spectrumT = torch.max(torch.stack(fake_Y_test_spectrums,0),0)[0]
                            labels_X_estimatedT = C_XtoY(fake_Y_test_spectrumT)
                            fake_Y_test_spectrumT2 = torch.max(torch.abs(torch.stack(fake_Y_test_spectrums,0)),0)[0]
                            labels_X_estimatedT2 = C_XtoY(fake_Y_test_spectrumT2)
                            labels_X_test_estimated1 = torch.round(torch.mode(labels_X_test_estimateds,0).values)
                            labels_X_test_estimated2 = torch.round(torch.mean(labels_X_test_estimateds,0))
                            labels_X_test_estimated3 = torch.round(torch.median(labels_X_test_estimateds,0).values)
                            labels_X_estimated4 = torch.mean(torch.stack(labels_X_estimateds),0)
                            labels_X_test_estimated4 = torch.max(labels_X_estimated4, 1)[1]

                            g_y_pix_loss = loss_spec(fake_Y_test_spectrum, images_Y_test_spectrum[0])
                            g_y_class_loss = loss_class(labels_X_estimated, labels_X_test)
                            G_Image_loss_avg_test[0] += g_y_pix_loss.item() 
                            G_Class_loss_avg_test[0] += g_y_class_loss.item() 

                            for i in range(opts.stack_imgs):
                                g_y_pix_loss = loss_spec(fake_Y_test_spectrums[i], images_Y_test_spectrum[0])
                                G_Image_loss_avg_test[i+1] += g_y_pix_loss.item() 
                                g_y_class_loss = loss_class(labels_X_estimateds[i], labels_X_test)
                                G_Class_loss_avg_test[i+1] += g_y_class_loss.item() 
                            g_y_class_loss = loss_class(labels_X_estimated4, labels_X_test)
                            G_Class_loss_avg_test[opts.stack_imgs+1] += g_y_class_loss.item() 

                            #get the answer
                            _, labels_X_test_estimated = torch.max(labels_X_estimated, 1)
                            _, labels_X_test_estimatedT = torch.max(labels_X_estimatedT, 1)
                            _, labels_X_test_estimatedT2 = torch.max(labels_X_estimatedT2, 1)
                            test_right_case = (labels_X_test_estimated == labels_X_test)
                            error_matrix[0] += np.sum(to_data(test_right_case))
                            test_right_case = (labels_X_test_estimated1 == labels_X_test)
                            error_matrix[1] += np.sum(to_data(test_right_case))
                            test_right_case = (labels_X_test_estimated2 == labels_X_test)
                            error_matrix[2] += np.sum(to_data(test_right_case))
                            test_right_case = (labels_X_test_estimated3 == labels_X_test)
                            error_matrix[3] += np.sum(to_data(test_right_case))
                            test_right_case = (labels_X_test_estimated4 == labels_X_test)
                            error_matrix[4] += np.sum(to_data(test_right_case))
                            test_right_case = (labels_X_test_estimatedT == labels_X_test)
                            error_matrix[5] += np.sum(to_data(test_right_case))
                            test_right_case = (labels_X_test_estimatedT2 == labels_X_test)
                            error_matrix[6] += np.sum(to_data(test_right_case))

                            error_matrix_count += opts.batch_size

                            if(iteration2==1):
                                print('---------')
                                save_samples(iteration+iteration2, images_Y_test_spectrum, images_X_test_spectrum, mask_CNN, opts)
                                print(labels_X_test_estimated,'common')
                                print(labels_X_test_estimated1,'mode')
                                print(labels_X_test_estimated2,'mean')
                                print(labels_X_test_estimated3,'median')
                                print(labels_X_test_estimated4,'meanoutput')
                                print(labels_X_test_estimateds)
                                print(labels_X_test,'truth')
                                print(labels_X_test_estimated == labels_X_test)
                                print(labels_X_test_estimated1 == labels_X_test)
                                print(labels_X_test_estimated2 == labels_X_test)
                                print(labels_X_test_estimated3 == labels_X_test)
                                print(labels_X_test_estimated4 == labels_X_test)

                    for i in range(4):
                        print(i, error_matrix[i] / error_matrix_count, G_Image_loss_avg_test[i] , G_Class_loss_avg_test[i])
                    print(G_Class_loss_avg_test[4])
                    print(error_matrix[4] / error_matrix_count)
                    print(error_matrix[5] / error_matrix_count)
                    print(error_matrix[6] / error_matrix_count)

                    '''
                    error_matrix2 = error_matrix / error_matrix_count
                    print('test accuracy',error_matrix2, error_matrix, error_matrix_count,'imgloss',G_Image_loss_avg_test/error_matrix_count*opts.batch_size*opts.scaling_for_imaging_loss ,'classloss',G_Class_loss_avg_test/error_matrix_count*opts.batch_size*opts.scaling_for_classification_loss,  'logged to', opts.logfile)
                    with open(opts.logfile,'a') as f:
                        f.write(str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")) + ' ' + str(iteration) +  ' ' + str(error_matrix2)+'\n')'''
    return mask_CNN, C_XtoY
